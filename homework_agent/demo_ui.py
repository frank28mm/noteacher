import base64
import uuid
import mimetypes
import os
import gradio as gr

from homework_agent.services.vision import VisionClient, VisionProvider
from homework_agent.services.llm import LLMClient
from homework_agent.models.schemas import ImageRef


def _encode_image(path: str) -> str:
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def _estimate_base64_size(b64: str) -> int:
    return int(len(b64) * 0.75)


def format_grading_result(result) -> str:
    md = f"## ğŸ“Š è¯„åˆ†ç»“æœ\n\n"
    md += f"**ç§‘ç›® (Subject)**: {result.subject.value}\n\n"
    md += f"**æ‘˜è¦ (Summary)**: {result.summary}\n\n"

    if result.wrong_items:
        md += "### âŒ é”™é¢˜åˆ—è¡¨\n"
        for idx, item in enumerate(result.wrong_items, 1):
            md += f"**{idx}.** {item.get('question_content', 'N/A')}\n"
            md += f"- é”™è¯¯åŸå› : {item.get('reason', 'N/A')}\n"
            if item.get("analysis"):
                md += f"- åˆ†æ: {item.get('analysis')}\n"
            bbox = item.get("bbox")
            if bbox:
                md += f"- ä½ç½® (BBox): `{bbox}`\n"
            md += "\n"
    else:
        md += "### âœ… å…¨å¯¹ (All Correct!)\nå¤ªæ£’äº†ï¼æ²¡æœ‰å‘ç°é”™è¯¯ã€‚\n"
    return md


def grade_homework_logic(img_path, img_url, subject, provider):
    """åŒæ­¥é€»è¾‘ï¼Œä¾› Gradio è§¦å‘"""
    # gr.File returns path string or object with .name
    if hasattr(img_path, "name"):
        img_path = img_path.name

    if not img_path and not img_url:
        return "**é”™è¯¯**ï¼šè¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶æˆ–æä¾›å…¬ç½‘ URLã€‚", None, []

    use_url = bool(img_url)
    if provider == "doubao" and not use_url:
        return "**é”™è¯¯**ï¼šDoubao åªæ”¯æŒå…¬ç½‘ URLã€‚è¯·å¡«å†™ URLã€‚", None, []

    try:
        img_refs = []
        if use_url:
            img_refs.append(ImageRef(url=img_url.strip()))
        else:
            b64 = _encode_image(img_path)
            if _estimate_base64_size(b64) > 20 * 1024 * 1024:
                return "**é”™è¯¯**ï¼šæ–‡ä»¶è¶…è¿‡ 20MBï¼Œè¯·æ”¹ç”¨ URLã€‚", None, []
            if provider != "qwen3":
                return "**é”™è¯¯**ï¼šå½“å‰ä»… Qwen3 æ”¯æŒ base64 å…œåº•ï¼Œè¯·ä½¿ç”¨ URL æˆ–åˆ‡æ¢ Qwen3ã€‚", None, []
            # mime, _ = mimetypes.guess_type(img_path)
            # mime = mime or "image/jpeg"
            # DEBUG: Force JPEG to rule out mime issues
            mime = "image/jpeg"
            
            data_uri = f"data:{mime};base64,{b64}"
            print(f"DEBUG: Generated Data URI head: {data_uri[:50]}...")
            img_refs.append(ImageRef(base64=data_uri))

        vis = VisionClient()
        vision_provider = VisionProvider.QWEN3 if provider == "qwen3" else VisionProvider.DOUBAO
        ocr_result = vis.analyze(images=img_refs, provider=vision_provider)

        llm = LLMClient()
        if subject == "math":
            grade_result = llm.grade_math(ocr_result.text, provider="silicon" if provider == "qwen3" else "ark")
        elif subject == "english":
            grade_result = llm.grade_english(ocr_result.text, provider="silicon" if provider == "qwen3" else "ark")
        else:
            return f"**é”™è¯¯**ï¼šæš‚ä¸æ”¯æŒå­¦ç§‘ {subject} çš„æ¼”ç¤ºã€‚", None, []

        md = format_grading_result(grade_result)
        options = [f"{i}:{item.get('reason','N/A')[:30]}" for i, item in enumerate(grade_result.wrong_items)]
        return md, grade_result, options
    except Exception as e:
        err_msg = str(e)
        if "20040" in err_msg:
            err_msg += " (æç¤ºï¼šæ¨¡å‹æ— æ³•ä¸‹è½½è¯¥ URLï¼Œå»ºè®®ç”¨æœ¬åœ°ä¸Šä¼ æˆ–å¯ç›´è¿çš„ CDN/OSS URL)"
        return f"**ç³»ç»Ÿé”™è¯¯**ï¼š{err_msg}", None, []


def tutor_chat_logic(message, history, grade_result, selected_items):
    history = history or []
    if not grade_result:
        response = "è¯·å…ˆåœ¨ã€æ™ºèƒ½æ‰¹æ”¹ã€‘æ ‡ç­¾é¡µå®Œæˆæ‰¹æ”¹ï¼Œæˆ‘éœ€è¦åŸºäºé”™é¢˜æ¥è¾…å¯¼ã€‚"
        history.append([message, response])
        return "", history

    try:
        if len(history) >= 5:
            history.append([message, "å·²è¾¾åˆ° 5 è½®ä¸Šé™ï¼Œå»ºè®®é‡æ–°å¼€å§‹ã€‚"])
            return "", history

        items = grade_result.wrong_items
        if selected_items:
            indices = []
            for s in selected_items:
                try:
                    idx = int(s.split(":", 1)[0])
                    indices.append(idx)
                except Exception:
                    continue
            items = [grade_result.wrong_items[i] for i in indices if 0 <= i < len(grade_result.wrong_items)]

        context = {"summary": grade_result.summary, "wrong_items": items}

        llm = LLMClient()
        tutor_result = llm.socratic_tutor(
            question=message,
            wrong_item_context=context,
            session_id=f"demo_{uuid.uuid4().hex[:8]}",
            interaction_count=len(history),
            provider="silicon",
        )

        assistant_msg = tutor_result.messages[0]["content"] if tutor_result.messages else "æ— å“åº”"
        history.append([message, assistant_msg])
        return "", history
    except Exception as e:
        history.append([message, f"ç³»ç»Ÿé”™è¯¯ï¼š{e}"])
        return "", history


def create_demo():
    with gr.Blocks(title="ä½œä¸šæ£€æŸ¥å¤§å¸ˆ (Homework Agent)") as demo:
        gr.Markdown("# ğŸ“ ä½œä¸šæ£€æŸ¥å¤§å¸ˆ (Homework Agent)\nURL ä¼˜å…ˆï¼ˆç¦æ­¢ localhost/127/å†…ç½‘ï¼Œå•æ–‡ä»¶â‰¤20MBï¼‰ã€‚Doubao ä»…æ”¯æŒ URLï¼›Qwen3 æ”¯æŒ URL æˆ– Base64 å…œåº•ã€‚")

        with gr.Tabs():
            with gr.Tab("ğŸ“ æ™ºèƒ½æ‰¹æ”¹"):
                with gr.Row():
                    with gr.Column(scale=1):
                        input_img = gr.File(label="ä¸Šä¼ å›¾ç‰‡ (File Upload)", file_types=["image"], height=300)
                        input_url = gr.Textbox(label="æˆ–è¾“å…¥å…¬ç½‘ URL", placeholder="https://...", lines=1)
                        subject_dropdown = gr.Dropdown(choices=["math", "english"], value="math", label="å­¦ç§‘ (Subject)")
                        provider_dropdown = gr.Dropdown(choices=["qwen3", "doubao"], value="qwen3", label="æ¨¡å‹ (Provider)")
                        grade_btn = gr.Button("å¼€å§‹æ‰¹æ”¹", variant="primary")
                    with gr.Column(scale=1):
                        output_md = gr.Markdown(label="æ‰¹æ”¹ç»“æœ")
                        raw_result_state = gr.State()
                        wrong_item_options = gr.State()

                grade_btn.click(
                    fn=grade_homework_logic,
                    inputs=[input_img, input_url, subject_dropdown, provider_dropdown],
                    outputs=[output_md, raw_result_state, wrong_item_options],
                )

            with gr.Tab("ğŸ‘©â€ğŸ« è‹æ ¼æ‹‰åº•è¾…å¯¼"):
                gr.Markdown("åŸºäºæ‰¹æ”¹ç»“æœè¿›è¡Œè¾…å¯¼ï¼Œå¯é€‰æ‹©é”™é¢˜ã€‚æœ€å¤š 5 è½®ã€‚")
                chatbot = gr.Chatbot(label="è¾…å¯¼å¯¹è¯", height=400)
                select_items = gr.CheckboxGroup(label="é€‰æ‹©è¦è®¨è®ºçš„é”™é¢˜", choices=[])
                msg = gr.Textbox(label="ä½ çš„é—®é¢˜", placeholder="è¿™é“é¢˜ä¸ºä»€ä¹ˆé”™äº†ï¼Ÿ")
                clear_btn = gr.Button("æ¸…é™¤å†å²")

                def update_choices(opts):
                    return gr.update(choices=opts)

                raw_result_state.change(fn=update_choices, inputs=wrong_item_options, outputs=select_items)

                msg.submit(
                    fn=tutor_chat_logic,
                    inputs=[msg, chatbot, raw_result_state, select_items],
                    outputs=[msg, chatbot],
                )
                clear_btn.click(lambda: None, None, chatbot, queue=False)

        gr.Markdown("""
        ---
        æ³¨æ„ï¼šæ¼”ç¤ºç‰ˆç›´è¿æ¨¡å‹ï¼ˆQwen3/Doubaoï¼‰ã€‚æ¨èä½¿ç”¨å…¬ç½‘ URLï¼›Base64 ä»…ç”¨äºå°å›¾å…œåº•ã€‚
        """)
    return demo


if __name__ == "__main__":
    os.environ["no_proxy"] = "localhost,127.0.0.1,0.0.0.0"
    demo = create_demo()
    demo.queue().launch(server_name="127.0.0.1", server_port=7890, show_error=True)
